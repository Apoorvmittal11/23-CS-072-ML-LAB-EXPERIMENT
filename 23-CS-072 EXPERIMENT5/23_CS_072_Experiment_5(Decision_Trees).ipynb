{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTtLjJ2SvYWykSiFh+9L7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apoorvmittal11/23-CS-072-ML-LAB-EXPERIMENT/blob/main/23-CS-072%20EXPERIMENT5/23_CS_072_Experiment_5(Decision_Trees).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective**\n",
        "\n",
        "In this assignment, you will implement a Decision Tree Classifier from scratch using numpy. and apply it to the Adult Income Dataset. The\n",
        "task is to predict whether a person earns more than $50K per year. You will\n",
        "build the tree, evaluate it, and perform both pre-pruning and post-pruning."
      ],
      "metadata": {
        "id": "xYTxA_rQbHdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**\n",
        "\n",
        "We will use the Adult Income Dataset from UCI.\n",
        "\n",
        "â€¢ Dataset link: Adult Dataset\n",
        "\n",
        "â€¢ Task: Binary classification (â‰¤ 50K vs. > 50K).\n",
        "\n",
        "â€¢ Features: Mix of categorical (e.g., workclass, education, occupation)\n",
        "and numeric (e.g., age, hours-per-week).\n",
        "\n",
        "â€¢ Target: Income."
      ],
      "metadata": {
        "id": "xW9HMDn6bHa2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Instructions**\n",
        "\n",
        "Use the following code to fetch the dataset:"
      ],
      "metadata": {
        "id": "q03t3InVbHX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goO29yUtbriI",
        "outputId": "c937a149-bb89-4c9b-bfff-b9d4579a4aca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "adult = fetch_ucirepo(id=2)\n",
        "X = adult.data.features # features (pandas DataFrame)\n",
        "y = adult.data.targets # target (pandas DataFrame)"
      ],
      "metadata": {
        "id": "XhpLG-2ScnN2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instructions**\n",
        "\n",
        "Follow these steps carefully. Do not skip any part."
      ],
      "metadata": {
        "id": "m6b9lLJObHU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Preparation**\n",
        "\n",
        "â€¢ Handle missing values (drop or impute).\n",
        "â€¢ Encode categorical variables into numeric values (e.g., label encoding).\n",
        "\n",
        "â€¢ Split the dataset as:\n",
        "\n",
        "â€“ 80% training\n",
        "\n",
        "â€“ 20% validation\n",
        "\n",
        "â€“ 20% test\n",
        "\n",
        "Use the validation set to tune depth and pruning."
      ],
      "metadata": {
        "id": "SRFAXfRdbHR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Combine features and target into one DataFrame\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Check first few rows\n",
        "print(\"Original Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Handle Missing Values\n",
        "# Replace '?' with NaN and drop rows containing missing values\n",
        "df = df.replace('?', pd.NA)\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode Categorical Variables\n",
        "label_encoders = {}\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Split Features and Target\n",
        "X = df.drop(columns=df.columns[-1])  # all columns except last one (target)\n",
        "y = df[df.columns[-1]]               # target column\n",
        "\n",
        "\n",
        "# Trainâ€“Validationâ€“Test Split\n",
        "# First split: 80% train + 20% temp\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Second split: 50-50 of the remaining 20% â†’ 10% val, 10% test\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "# Check the resulting shapes\n",
        "print(\"Training set:\", X_train.shape)\n",
        "print(\"Validation set:\", X_val.shape)\n",
        "print(\"Test set:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPsbeErOdG4u",
        "outputId": "1f1e06e9-7786-49cf-880f-cca89b4162a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "   age         workclass  fnlwgt  education  education-num  \\\n",
            "0   39         State-gov   77516  Bachelors             13   \n",
            "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
            "2   38           Private  215646    HS-grad              9   \n",
            "3   53           Private  234721       11th              7   \n",
            "4   28           Private  338409  Bachelors             13   \n",
            "\n",
            "       marital-status         occupation   relationship   race     sex  \\\n",
            "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
            "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
            "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
            "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
            "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
            "\n",
            "   capital-gain  capital-loss  hours-per-week native-country income  \n",
            "0          2174             0              40  United-States  <=50K  \n",
            "1             0             0              13  United-States  <=50K  \n",
            "2             0             0              40  United-States  <=50K  \n",
            "3             0             0              40  United-States  <=50K  \n",
            "4             0             0              40           Cuba  <=50K  \n",
            "Training set: (36177, 14)\n",
            "Validation set: (4522, 14)\n",
            "Test set: (4523, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Build a Decision Tree From Scratch**\n",
        "\n",
        "â€¢ Implement a tree recursively.\n",
        "\n",
        "â€¢ At each split:\n",
        "\n",
        "1. Compute both Gini Impurity and Entropy.\n",
        "\n",
        "2. For each feature and split, calculate the weighted impurity of child\n",
        "nodes.\n",
        "\n",
        "3. Choose the split with the highest information gain (lowest impu-\n",
        "rity).\n",
        "\n",
        "â€¢ Continue splitting until:\n",
        "\n",
        "â€“ All samples in a node have the same label, OR\n",
        "\n",
        "â€“ Maximum depth is reached, OR\n",
        "\n",
        "â€“ No further improvement in impurity.\n",
        "\n",
        "â€¢ Implement a function to predict for new samples."
      ],
      "metadata": {
        "id": "f1krAv1nbHOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# ----- Helper Functions -----\n",
        "\n",
        "def entropy(y):\n",
        "    counts = np.bincount(y)\n",
        "    probabilities = counts / len(y)\n",
        "    return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
        "\n",
        "def gini(y):\n",
        "    counts = np.bincount(y)\n",
        "    probabilities = counts / len(y)\n",
        "    return 1 - np.sum(probabilities ** 2)\n",
        "\n",
        "def information_gain(y, y_left, y_right, criterion='gini'):\n",
        "    if len(y_left) == 0 or len(y_right) == 0:\n",
        "        return 0\n",
        "    if criterion == 'gini':\n",
        "        parent_impurity = gini(y)\n",
        "        left_impurity = gini(y_left)\n",
        "        right_impurity = gini(y_right)\n",
        "    else:\n",
        "        parent_impurity = entropy(y)\n",
        "        left_impurity = entropy(y_left)\n",
        "        right_impurity = entropy(y_right)\n",
        "    n = len(y)\n",
        "    n_left, n_right = len(y_left), len(y_right)\n",
        "    weighted_impurity = (n_left/n) * left_impurity + (n_right/n) * right_impurity\n",
        "    return parent_impurity - weighted_impurity\n",
        "\n",
        "\n",
        "# ----- Decision Tree Implementation -----\n",
        "\n",
        "class DecisionTreeFromScratch:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, criterion='gini'):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y, depth=0):\n",
        "        if len(set(y)) == 1 or len(y) < self.min_samples_split or \\\n",
        "           (self.max_depth is not None and depth >= self.max_depth):\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        best_gain = -1\n",
        "        best_split = None\n",
        "\n",
        "        for feature_idx in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for t in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= t\n",
        "                right_mask = ~left_mask\n",
        "                y_left, y_right = y[left_mask], y[right_mask]\n",
        "                gain = information_gain(y, y_left, y_right, self.criterion)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_split = (feature_idx, t, y_left, y_right, left_mask, right_mask)\n",
        "\n",
        "        if best_gain == 0 or best_split is None:\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "        feature_idx, threshold, _, _, left_mask, right_mask = best_split\n",
        "        left_branch = self.fit(X[left_mask], y[left_mask], depth+1)\n",
        "        right_branch = self.fit(X[right_mask], y[right_mask], depth+1)\n",
        "        return (feature_idx, threshold, left_branch, right_branch)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.tree = self.fit(X, y)\n",
        "\n",
        "    def predict_one(self, x, node):\n",
        "        if not isinstance(node, tuple):\n",
        "            return node\n",
        "        feature_idx, threshold, left, right = node\n",
        "        if x[feature_idx] <= threshold:\n",
        "            return self.predict_one(x, left)\n",
        "        else:\n",
        "            return self.predict_one(x, right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.predict_one(x, self.tree) for x in X])\n"
      ],
      "metadata": {
        "id": "DmQ0nGjJeElf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to numpy arrays\n",
        "X_np = X_train.to_numpy()\n",
        "y_np = y_train.to_numpy().ravel()\n",
        "y_val_np = y_val.to_numpy().ravel()\n",
        "\n",
        "# Train with entropy criterion\n",
        "tree = DecisionTreeFromScratch(max_depth=4, criterion='entropy')\n",
        "tree.train(X_np, y_np)\n",
        "\n",
        "# Predict\n",
        "y_pred = tree.predict(X_val.to_numpy())\n",
        "accuracy = (y_pred == y_val_np).mean()\n",
        "print(f\"Validation Accuracy: {accuracy:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6tkOQjteW0d",
        "outputId": "e5689bc3-8e32-4670-d679-db3e93cf8cf0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Pre-Pruning (Restricting Tree Growth)**\n",
        "\n",
        "While building the tree:\n",
        "\n",
        "â€¢ Limit maximum depth (try depths = 2, 4, 6, and unlimited).\n",
        "\n",
        "â€¢ Require at least a minimum number of samples (e.g., 5) to split.\n",
        "\n",
        "â€¢ Require a minimum impurity decrease (optional)."
      ],
      "metadata": {
        "id": "AIEsb5kGbHHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "# Impurity functions\n",
        "def gini_impurity(y):\n",
        "    counts = Counter(y)\n",
        "    n = len(y)\n",
        "    return 1.0 - sum((count / n) ** 2 for count in counts.values())\n",
        "\n",
        "def entropy(y):\n",
        "    counts = Counter(y)\n",
        "    n = len(y)\n",
        "    return -sum((count / n) * math.log2(count / n) for count in counts.values())\n",
        "\n",
        "# Split function\n",
        "def split_dataset(X, y, feature, threshold):\n",
        "    left_mask = X[feature] <= threshold\n",
        "    right_mask = X[feature] > threshold\n",
        "    return X[left_mask], X[right_mask], y[left_mask], y[right_mask]\n",
        "\n",
        "# Information gain\n",
        "def information_gain(y, y_left, y_right, criterion='gini'):\n",
        "    impurity_func = gini_impurity if criterion == 'gini' else entropy\n",
        "    parent_impurity = impurity_func(y)\n",
        "    n = len(y)\n",
        "    n_left, n_right = len(y_left), len(y_right)\n",
        "    if n_left == 0 or n_right == 0:\n",
        "        return 0\n",
        "    weighted_impurity = (n_left / n) * impurity_func(y_left) + (n_right / n) * impurity_func(y_right)\n",
        "    return parent_impurity - weighted_impurity\n",
        "\n",
        "# Node structure\n",
        "class DecisionTreeNode:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "# Decision Tree Class with Pre-Pruning\n",
        "class DecisionTreeFromScratch:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, min_impurity_decrease=0.0, criterion='gini'):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_impurity_decrease = min_impurity_decrease\n",
        "        self.criterion = criterion\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y, depth=0):\n",
        "        # Pre-Pruning conditions\n",
        "        if len(set(y)) == 1:\n",
        "            return DecisionTreeNode(value=y.iloc[0])\n",
        "\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return DecisionTreeNode(value=y.mode()[0])\n",
        "\n",
        "        if len(y) < self.min_samples_split:\n",
        "            return DecisionTreeNode(value=y.mode()[0])\n",
        "\n",
        "        best_gain = 0\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "        best_splits = None\n",
        "\n",
        "        # Try all features and thresholds\n",
        "        for feature in X.columns:\n",
        "            for threshold in np.unique(X[feature]):\n",
        "                X_left, X_right, y_left, y_right = split_dataset(X, y, feature, threshold)\n",
        "                if len(y_left) == 0 or len(y_right) == 0:\n",
        "                    continue\n",
        "                gain = information_gain(y, y_left, y_right, self.criterion)\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "                    best_splits = (X_left, X_right, y_left, y_right)\n",
        "\n",
        "        # Stop if gain is too small (pre-pruning condition)\n",
        "        if best_gain < self.min_impurity_decrease or best_splits is None:\n",
        "            return DecisionTreeNode(value=y.mode()[0])\n",
        "\n",
        "        # Recursive building\n",
        "        left_subtree = self.fit(best_splits[0], best_splits[2], depth + 1)\n",
        "        right_subtree = self.fit(best_splits[1], best_splits[3], depth + 1)\n",
        "        return DecisionTreeNode(feature=best_feature, threshold=best_threshold, left=left_subtree, right=right_subtree)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.root = self.fit(X, y)\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._predict_one(x, node.left)\n",
        "        else:\n",
        "            return self._predict_one(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return X.apply(lambda row: self._predict_one(row, self.root), axis=1)\n"
      ],
      "metadata": {
        "id": "tMJsI_Qie6FB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for depth in [2, 4, 6, None]:  # None means unlimited depth\n",
        "    tree = DecisionTreeFromScratch(\n",
        "        max_depth=depth,\n",
        "        min_samples_split=5,  # pre-pruning condition\n",
        "        criterion='gini'\n",
        "    )\n",
        "    tree.train(X_train.to_numpy(), y_train.to_numpy().ravel())\n",
        "    y_pred = tree.predict(X_val.to_numpy())\n",
        "    acc = (y_pred == y_val.to_numpy().ravel()).mean()\n",
        "    print(f\"Depth={depth if depth else 'Unlimited'} â†’ Validation Accuracy: {acc:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDAjFuVNgk6t",
        "outputId": "e92796e4-59ab-4479-ce08-212af8abec8d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth=2 â†’ Validation Accuracy: 0.551\n",
            "Depth=4 â†’ Validation Accuracy: 0.564\n",
            "Depth=6 â†’ Validation Accuracy: 0.566\n",
            "Depth=Unlimited â†’ Validation Accuracy: 0.449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Post-Pruning (Reduced Error Pruning)**\n",
        "\n",
        "1. First grow a full tree.\n",
        "\n",
        "2. Then, for each internal node:\n",
        "\n",
        "â€¢ Replace it with a leaf (majority class).\n",
        "\n",
        "â€¢ Check validation accuracy.\n",
        "\n",
        "3. If accuracy does not decrease, keep the pruning.\n",
        "\n",
        "4. Repeat until no further improvement."
      ],
      "metadata": {
        "id": "WihIfin1fgj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class DecisionTreeFromScratch:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, criterion='gini'):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "    # ----- Impurity Functions -----\n",
        "    def entropy(self, y):\n",
        "        counts = np.bincount(y)\n",
        "        probs = counts / len(y)\n",
        "        return -np.sum([p * np.log2(p) for p in probs if p > 0])\n",
        "\n",
        "    def gini(self, y):\n",
        "        counts = np.bincount(y)\n",
        "        probs = counts / len(y)\n",
        "        return 1 - np.sum(probs ** 2)\n",
        "\n",
        "    def information_gain(self, y, y_left, y_right):\n",
        "        if len(y_left) == 0 or len(y_right) == 0:\n",
        "            return 0\n",
        "        impurity = self.gini if self.criterion == 'gini' else self.entropy\n",
        "        n = len(y)\n",
        "        return impurity(y) - (len(y_left)/n)*impurity(y_left) - (len(y_right)/n)*impurity(y_right)\n",
        "\n",
        "    # ----- Recursive Tree Building -----\n",
        "    def fit(self, X, y, depth=0):\n",
        "        # Stopping conditions\n",
        "        if len(set(y)) == 1:\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "        if len(y) < self.min_samples_split:\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "        if depth >= 50:  # safety cap to avoid infinite recursion\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        best_gain = 0\n",
        "        best_split = None\n",
        "\n",
        "        for feature_idx in range(n_features):\n",
        "            values = np.unique(X[:, feature_idx])\n",
        "            if len(values) <= 1:\n",
        "                continue\n",
        "            thresholds = (values[:-1] + values[1:]) / 2  # midpoints\n",
        "            for t in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= t\n",
        "                right_mask = ~left_mask\n",
        "                if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
        "                    continue\n",
        "                gain = self.information_gain(y, y[left_mask], y[right_mask])\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_split = (feature_idx, t, left_mask, right_mask)\n",
        "\n",
        "        if best_split is None or best_gain <= 0:\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "        feature_idx, threshold, left_mask, right_mask = best_split\n",
        "        left_branch = self.fit(X[left_mask], y[left_mask], depth + 1)\n",
        "        right_branch = self.fit(X[right_mask], y[right_mask], depth + 1)\n",
        "        return (feature_idx, threshold, left_branch, right_branch)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.tree = self.fit(X, y)\n",
        "\n",
        "    def predict_one(self, x, node):\n",
        "        if not isinstance(node, tuple):\n",
        "            return node\n",
        "        feature_idx, threshold, left, right = node\n",
        "        return self.predict_one(x, left) if x[feature_idx] <= threshold else self.predict_one(x, right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.predict_one(x, self.tree) for x in X])\n"
      ],
      "metadata": {
        "id": "Urpx03acff2A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeFromScratch(max_depth=None, min_samples_split=5, criterion='gini')\n",
        "tree.train(X_train.to_numpy(), y_train.to_numpy().ravel())\n",
        "\n",
        "y_pred = tree.predict(X_val.to_numpy())\n",
        "acc = (y_pred == y_val.to_numpy().ravel()).mean()\n",
        "print(f\"Validation Accuracy: {acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_rrKCH3jeNf",
        "outputId": "9f85fb7c-0c77-4745-c324-1c012ea28939"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Evaluation**\n",
        "\n",
        "â€¢ Train using the training set.\n",
        "\n",
        "â€¢ Tune depth and pruning using validation set.\n",
        "\n",
        "â€¢ Report final results on test set.\n",
        "\n",
        "â€¢ Metrics to report:\n",
        "\n",
        "â€“ Accuracy\n",
        "\n",
        "â€“ Precision, Recall, F1-score\n",
        "\n",
        "â€“ Confusion Matrix\n",
        "\n",
        "â€¢ Compare your implementation with sklearn.tree.DecisionTreeClassifier."
      ],
      "metadata": {
        "id": "v6ju_Uo-fhIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Convert to numpy\n",
        "X_train_np = X_train.to_numpy()\n",
        "y_train_np = y_train.to_numpy().ravel()\n",
        "X_val_np = X_val.to_numpy()\n",
        "y_val_np = y_val.to_numpy().ravel()\n",
        "X_test_np = X_test.to_numpy()\n",
        "y_test_np = y_test.to_numpy().ravel()\n",
        "\n",
        "# Tune max_depth using validation accuracy\n",
        "best_depth = None\n",
        "best_acc = 0\n",
        "\n",
        "for depth in [2, 4, 6, 8, None]:\n",
        "    tree = DecisionTreeFromScratch(max_depth=depth, min_samples_split=5, criterion='gini')\n",
        "    tree.train(X_train_np, y_train_np)\n",
        "    y_pred_val = tree.predict(X_val_np)\n",
        "    acc = accuracy_score(y_val_np, y_pred_val)\n",
        "    print(f\"Depth={depth if depth else 'Unlimited'} â†’ Validation Accuracy: {acc:.3f}\")\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_depth = depth\n",
        "\n",
        "print(f\"\\nBest depth based on validation: {best_depth}\\n\")\n",
        "\n",
        "# Retrain best model on train + val and test on test set\n",
        "# Merge train + validation for final training\n",
        "X_final = np.concatenate([X_train_np, X_val_np])\n",
        "y_final = np.concatenate([y_train_np, y_val_np])\n",
        "\n",
        "# Train final model\n",
        "final_tree = DecisionTreeFromScratch(max_depth=best_depth, min_samples_split=5, criterion='gini')\n",
        "final_tree.train(X_final, y_final)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_test = final_tree.predict(X_test_np)\n",
        "\n",
        "# Metrics (Accuracy, Precision, Recall, F1, Confusion Matrix)\n",
        "acc = accuracy_score(y_test_np, y_pred_test)\n",
        "prec = precision_score(y_test_np, y_pred_test, average='weighted', zero_division=0)\n",
        "rec = recall_score(y_test_np, y_pred_test, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test_np, y_pred_test, average='weighted', zero_division=0)\n",
        "cm = confusion_matrix(y_test_np, y_pred_test)\n",
        "\n",
        "print(\"=== Custom Decision Tree Performance ===\")\n",
        "print(f\"Accuracy : {acc:.3f}\")\n",
        "print(f\"Precision: {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1-Score : {f1:.3f}\")\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# Compare with sklearn's DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(max_depth=best_depth, min_samples_split=5, criterion='gini', random_state=42)\n",
        "clf.fit(X_final, y_final)\n",
        "y_pred_sklearn = clf.predict(X_test_np)\n",
        "\n",
        "acc_sk = accuracy_score(y_test_np, y_pred_sklearn)\n",
        "prec_sk = precision_score(y_test_np, y_pred_sklearn, average='weighted', zero_division=0)\n",
        "rec_sk = recall_score(y_test_np, y_pred_sklearn, average='weighted', zero_division=0)\n",
        "f1_sk = f1_score(y_test_np, y_pred_sklearn, average='weighted', zero_division=0)\n",
        "cm_sk = confusion_matrix(y_test_np, y_pred_sklearn)\n",
        "\n",
        "print(\"\\n=== sklearn.tree.DecisionTreeClassifier Performance ===\")\n",
        "print(f\"Accuracy : {acc_sk:.3f}\")\n",
        "print(f\"Precision: {prec_sk:.3f}\")\n",
        "print(f\"Recall   : {rec_sk:.3f}\")\n",
        "print(f\"F1-Score : {f1_sk:.3f}\")\n",
        "print(\"\\nConfusion Matrix:\\n\", cm_sk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykFnXuJ4f_R1",
        "outputId": "4cff425c-c365-4d39-e2c1-dbc652ccdd1b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth=2 â†’ Validation Accuracy: 0.551\n",
            "Depth=4 â†’ Validation Accuracy: 0.564\n",
            "Depth=6 â†’ Validation Accuracy: 0.566\n",
            "Depth=8 â†’ Validation Accuracy: 0.568\n",
            "Depth=Unlimited â†’ Validation Accuracy: 0.455\n",
            "\n",
            "âœ… Best depth based on validation: 8\n",
            "\n",
            "=== Custom Decision Tree Performance ===\n",
            "Accuracy : 0.565\n",
            "Precision: 0.503\n",
            "Recall   : 0.565\n",
            "F1-Score : 0.455\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2111   16  101    2]\n",
            " [1090   12   50    3]\n",
            " [ 335    1  425   15]\n",
            " [ 148    1  204    9]]\n",
            "\n",
            "=== sklearn.tree.DecisionTreeClassifier Performance ===\n",
            "Accuracy : 0.565\n",
            "Precision: 0.492\n",
            "Recall   : 0.565\n",
            "F1-Score : 0.454\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2111   16  101    2]\n",
            " [1091   11   50    3]\n",
            " [ 335    1  425   15]\n",
            " [ 148    2  204    8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Experiments to Perform**\n",
        "\n",
        "â€¢ Compare Gini vs. Entropy.\n",
        "\n",
        "â€¢ Compare different depths (2, 4, 6, unlimited).\n",
        "\n",
        "â€¢ Show effect of pruning (pre-pruned vs. post-pruned vs. full tree).\n",
        "\n",
        "â€¢ Identify the most important features (which features are used at the\n",
        "top of the tree)."
      ],
      "metadata": {
        "id": "9L9VLgJMf_la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gini vs. Entropy\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "criteria = ['gini', 'entropy']\n",
        "results = []\n",
        "\n",
        "for criterion in criteria:\n",
        "    clf = DecisionTreeClassifier(criterion=criterion, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_val)\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    results.append({'Criterion': criterion, 'Validation Accuracy': acc})\n",
        "\n",
        "gini_entropy_results = pd.DataFrame(results)\n",
        "print(\"ðŸ”¹ Gini vs Entropy Comparison:\\n\")\n",
        "print(gini_entropy_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kbI5W3agPmp",
        "outputId": "3fc294bb-d126-425a-dff4-29a995a644ce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Gini vs Entropy Comparison:\n",
            "\n",
            "  Criterion  Validation Accuracy\n",
            "0      gini             0.443609\n",
            "1   entropy             0.447590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare different depths (2, 4, 6, unlimited).\n",
        "depths = [2, 4, 6, None]  # None = unlimited depth\n",
        "depth_results = []\n",
        "\n",
        "for d in depths:\n",
        "    clf = DecisionTreeClassifier(max_depth=d, criterion='gini', random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred_val = clf.predict(X_val)\n",
        "    acc_val = accuracy_score(y_val, y_pred_val)\n",
        "    depth_results.append({'Max Depth': d if d else 'Full', 'Validation Accuracy': acc_val})\n",
        "\n",
        "depth_results_df = pd.DataFrame(depth_results)\n",
        "print(\"\\nðŸ”¹ Effect of Tree Depth:\\n\")\n",
        "print(depth_results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKIvuzeanKW9",
        "outputId": "a9dd616b-45e4-4f1e-a467-43655b114e54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Effect of Tree Depth:\n",
            "\n",
            "  Max Depth  Validation Accuracy\n",
            "0         2             0.550641\n",
            "1         4             0.563689\n",
            "2         6             0.566342\n",
            "3      Full             0.443609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show effect of pruning (pre-pruned vs. post-pruned vs. full tree).\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Full tree (no pruning)\n",
        "full_tree = DecisionTreeClassifier(random_state=42)\n",
        "full_tree.fit(X_train, y_train)\n",
        "full_acc = accuracy_score(y_val, full_tree.predict(X_val))\n",
        "\n",
        "# Pre-pruned (max_depth=4)\n",
        "prepruned_tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
        "prepruned_tree.fit(X_train, y_train)\n",
        "pre_acc = accuracy_score(y_val, prepruned_tree.predict(X_val))\n",
        "\n",
        "# --- Optimized Post-Pruning ---\n",
        "path = full_tree.cost_complexity_pruning_path(X_train, y_train)\n",
        "\n",
        "# Instead of testing every alpha, test only a few representative ones\n",
        "ccp_alphas = np.linspace(path.ccp_alphas.min(), path.ccp_alphas.max(), 10)  # 10 values instead of hundreds\n",
        "\n",
        "best_acc = 0\n",
        "best_alpha = 0\n",
        "\n",
        "for alpha in ccp_alphas:\n",
        "    pruned_tree = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)\n",
        "    pruned_tree.fit(X_train, y_train)\n",
        "    acc = accuracy_score(y_val, pruned_tree.predict(X_val))\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_alpha = alpha\n",
        "\n",
        "print(\"\\nðŸ”¹ Pruning Comparison (Optimized):\")\n",
        "print(f\"Full tree accuracy: {full_acc:.4f}\")\n",
        "print(f\"Pre-pruned tree (depth=4): {pre_acc:.4f}\")\n",
        "print(f\"Best post-pruned accuracy: {best_acc:.4f} (alpha={best_alpha:.5f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsxge7jdpc9h",
        "outputId": "432fb96b-dfed-430d-9613-0115f51e9583"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Pruning Comparison (Optimized):\n",
            "Full tree accuracy: 0.4436\n",
            "Pre-pruned tree (depth=4): 0.5637\n",
            "Best post-pruned accuracy: 0.5628 (alpha=0.00370)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Identify the most important features (which features are used at the top of the tree).\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "best_clf = DecisionTreeClassifier(max_depth=None, criterion='gini', random_state=42)\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "feature_importances = pd.Series(best_clf.feature_importances_, index=X_train.columns)\n",
        "feature_importances = feature_importances.sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nðŸ”¹ Top 10 Most Important Features:\\n\")\n",
        "print(feature_importances.head(10))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "feature_importances.head(10).plot(kind='barh')\n",
        "plt.title(\"Top 10 Important Features in Decision Tree\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "DF7SQh0rnK_v",
        "outputId": "27870671-fcb1-42c2-ff74-99e01f619085"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Top 10 Most Important Features:\n",
            "\n",
            "fnlwgt            0.297837\n",
            "age               0.160886\n",
            "occupation        0.096137\n",
            "hours-per-week    0.090790\n",
            "relationship      0.079464\n",
            "education-num     0.064835\n",
            "capital-gain      0.046076\n",
            "workclass         0.040757\n",
            "education         0.032603\n",
            "native-country    0.020590\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}